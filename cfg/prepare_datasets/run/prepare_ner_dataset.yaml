# @package _global_
defaults:
  - /args/data_args: "???"

args:
  analyzer_args:
    analyzer_output_dir: ${oc.env:TORCH_FUSION_OUTPUT_DIR}/analyzer/
    tasks:
      prepare_dataset:
        task_type: PrepareDataset
        task_config: 
          visualize: True
  data_args:
    num_proc: 1
    dataset_config_name: ${dataset_config_name}
    train_preprocess_augs: null
    eval_preprocess_augs: null
    train_realtime_augs: null
    eval_realtime_augs: null
    dataset_kwargs:
      tokenizer_config: 
        model_name: hf_tokenizer
        kwargs: 
          model_name: bert-base-uncased
          init_kwargs:
            local_files_only: False
            add_prefix_space: True
            do_lower_case: True
          call_kwargs:
            add_special_tokens: True
            padding: "max_length"
            truncation: True
            max_length: 512
            stride: 0
            pad_to_multiple_of: 8
          # post processing padding args
          padding_required: True
          padding_side: right

hydra:
  run:
    dir: ${args.analyzer_args.analyzer_output_dir}/${args.data_args.dataset_name}/
  output_subdir: hydra
  job:
    chdir: False

dataset_config_name: default
