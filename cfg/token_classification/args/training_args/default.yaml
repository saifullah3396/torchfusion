experiment_name: default
clear_cuda_cache: true
cutmixup_args:
  cutmix: 0
  cutmix_minmax: null
  mixup: 0
  mixup_mode: batch
  mixup_prob: 1.0
  mixup_switch_prob: 0.5
early_stopping_args:
  cumulative_delta: false
  min_delta: 0.0
  mode: min
  monitored_metric: null # val/loss
  patience: 5
enable_checkpointing: true
enable_grad_clipping: false
eval_on_start: true
gradient_accumulation_steps: 2
log_gpu_stats: False
log_to_tb: true
logging_steps: 10
lr_schedulers: null
eval_every_n_epochs: 1
max_epochs: 100
max_grad_norm: 1.0
min_epochs: null
model_checkpoint_config:
  dir: checkpoints
  every_n_epochs: 1
  every_n_steps: null
  mode: max # min
  monitored_metric: validation/f1
  n_best_saved: 1
  n_saved: 1
  name_prefix: ""
  save_weights_only: false
model_ema_args:
  enabled: false
  momentum: 0.0001
  update_every: 1
  # momentum_warmup: 0.999 # start from online model
  # warmup_iters: 1000
non_blocking_tensor_conv: false
optimizers:
  default:
    group_params:
      - group_name: default
        kwargs:
          betas:
            - 0.9
            - 0.999
          eps: 1.0e-08
          lr: 2.0e-05
          weight_decay: 0.0
    name: adam
  # default:
  #   group_params:
  #     - group_name: default
  #       kwargs:
  #         lr: 0.01
  #         weight_decay: 1.0e-4
  #   name: sgd
resume_checkpoint_file: null
resume_from_checkpoint: true
smoothing: 0.0
stop_on_nan: true
sync_batchnorm: true
test_checkpoint_file: null
warmup_ratio: 0.2 # 2 epochs
warmup_steps: 0
wd_schedulers: null
with_amp: True
load_best_checkpoint_resume: false
outputs_to_metric:
  - loss